{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":104857,"databundleVersionId":12651513,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom catboost import CatBoostRegressor, Pool\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T04:59:45.030911Z","iopub.execute_input":"2025-06-14T04:59:45.031381Z","iopub.status.idle":"2025-06-14T04:59:45.036192Z","shell.execute_reply.started":"2025-06-14T04:59:45.031357Z","shell.execute_reply":"2025-06-14T04:59:45.035427Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# =============================================================\n# PureÂ XGBoost lapâ€‘time predictor (single split, early stopping)\n# =============================================================\n!pip install --quiet xgboost==2.0.3 pandas==2.2.2\n\nimport pandas as pd, numpy as np, os, xgboost as xgb, time, gc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\n# â”€â”€ 1.  Paths & column names â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDATA_DIR = \"/kaggle/input/burnout-datathon-ieeecsmuj\"   \nTARGET   = \"Lap_Time_Seconds\"                # â¬…ï¸ lapâ€‘time column\nID_COL   = \"Unique ID\"                       # â¬…ï¸ ID column for submission\n\ntrain_df = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"))\ntest_df  = pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"))\nprint(\"Train shape:\", train_df.shape, \"Â Â Test shape:\", test_df.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T08:46:18.697957Z","iopub.execute_input":"2025-06-14T08:46:18.698356Z","iopub.status.idle":"2025-06-14T08:46:46.503226Z","shell.execute_reply.started":"2025-06-14T08:46:18.698324Z","shell.execute_reply":"2025-06-14T08:46:46.502108Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.1 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mTrain shape: (1914056, 45) Â Â Test shape: (546874, 44)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# â”€â”€ 2.  Minimal feature engineering (checks each column) â”€â”€â”€â”€\ndef add_features(df):\n    if {\"Circuit_Length_km\", \"Avg_Speed_kmh\"}.issubset(df.columns):\n        df[\"secs_per_km\"] = (df[\"Circuit_Length_km\"] / df[\"Avg_Speed_kmh\"]) * 3600\n    if {\"Track_Temperature_Celsius\", \"Ambient_Temperature_Celsius\"}.issubset(df.columns):\n        df[\"track_minus_air\"] = df[\"Track_Temperature_Celsius\"] - df[\"Ambient_Temperature_Celsius\"]\n    if \"Track_Condition\" in df.columns:\n        df[\"is_wet\"] = df[\"Track_Condition\"].str.contains(\"Wet\", case=False, na=False).astype(int)\n    if {\"Tire_Compound_Front\", \"Tire_Compound_Rear\"}.issubset(df.columns):\n        df[\"tire_combo\"] = df[\"Tire_Compound_Front\"].fillna(\"\") + \"_\" + df[\"Tire_Compound_Rear\"].fillna(\"\")\n    return df\n\ntrain_df = add_features(train_df);  test_df = add_features(test_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T08:47:17.759703Z","iopub.execute_input":"2025-06-14T08:47:17.762032Z","iopub.status.idle":"2025-06-14T08:47:20.363442Z","shell.execute_reply.started":"2025-06-14T08:47:17.761977Z","shell.execute_reply":"2025-06-14T08:47:20.362467Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# â”€â”€ 3.  Convert position numeric â†’ categorical string (if present) â”€â”€\nif \"position\" in train_df.columns:\n    train_df[\"Position_cat\"] = train_df[\"position\"].astype(str)\n    test_df[\"Position_cat\"]  = test_df[\"position\"].astype(str)\n    train_df.drop(columns=[\"position\"], inplace=True)\n    test_df.drop(columns=[\"position\"],  inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T08:48:46.885702Z","iopub.execute_input":"2025-06-14T08:48:46.886298Z","iopub.status.idle":"2025-06-14T08:48:48.581109Z","shell.execute_reply.started":"2025-06-14T08:48:46.886173Z","shell.execute_reply":"2025-06-14T08:48:48.580155Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# â”€â”€ 4.  Identify categorical & numeric columns robustly â”€â”€â”€â”€â”€â”€\ncat_cols = [c for c in train_df.columns\n            if train_df[c].dtype == \"object\" or train_df[c].dtype.name == \"category\"]\nnum_cols = [c for c in train_df.columns if c not in cat_cols + [TARGET]]\n\n# Keep only cats present in both frames\ncat_cols = [c for c in cat_cols if c in test_df.columns]\n\n# Fill NaNs\ntrain_df[cat_cols] = train_df[cat_cols].fillna(\"missing\")\ntest_df[cat_cols]  = test_df[cat_cols].fillna(\"missing\")\nfor col in num_cols:\n    med = train_df[col].median()\n    train_df[col].fillna(med, inplace=True)\n    test_df[col].fillna(med,  inplace=True)\n\n# Cast categorical dtype for XGB native cats\nfor c in cat_cols:\n    train_df[c] = train_df[c].astype(\"category\")\n    test_df[c]  = test_df[c].astype(\"category\")\n\nfeature_cols = cat_cols + num_cols\nprint(f\"Using {len(feature_cols)} features ({len(cat_cols)} categorical).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T08:49:02.547047Z","iopub.execute_input":"2025-06-14T08:49:02.547397Z","iopub.status.idle":"2025-06-14T08:49:11.899774Z","shell.execute_reply.started":"2025-06-14T08:49:02.547373Z","shell.execute_reply":"2025-06-14T08:49:11.898775Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/41244590.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_df[col].fillna(med, inplace=True)\n/tmp/ipykernel_35/41244590.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  test_df[col].fillna(med,  inplace=True)\n","output_type":"stream"},{"name":"stdout","text":"Using 48 features (15 categorical).\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# â”€â”€ 5.  Trainâ€‘validation split â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nX_train, X_val, y_train, y_val = train_test_split(\n    train_df[feature_cols], train_df[TARGET],\n    test_size=0.2, random_state=42\n)\n\ndtrain = xgb.DMatrix(X_train, label=y_train, enable_categorical=True)\ndval   = xgb.DMatrix(X_val,   label=y_val,   enable_categorical=True)\ndtest  = xgb.DMatrix(test_df[feature_cols], enable_categorical=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T08:49:18.163760Z","iopub.execute_input":"2025-06-14T08:49:18.164081Z","iopub.status.idle":"2025-06-14T08:49:22.336576Z","shell.execute_reply.started":"2025-06-14T08:49:18.164057Z","shell.execute_reply":"2025-06-14T08:49:22.335911Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# â”€â”€ 6.  XGBoost parameters & training â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nparams = {\n    \"objective\": \"reg:squarederror\",\n    \"eval_metric\": \"rmse\",\n    \"learning_rate\": 0.05,\n    \"max_depth\": 8,\n    \"subsample\": 0.8,\n    \"colsample_bytree\": 0.8,\n    \"min_child_weight\": 10,\n    \"lambda\": 3.0,\n    \"tree_method\": \"hist\",          # â¡ â€œgpu_histâ€ if you enabled GPU runtime\n    \"enable_categorical\": True,\n    \"seed\": 42,\n}\n\nstart = time.time()\nmodel = xgb.train(\n    params,\n    dtrain,\n    num_boost_round=5000,\n    evals=[(dval, \"val\")],\n    early_stopping_rounds=200,\n    verbose_eval=250\n)\nprint(f\"â±ï¸  Training time: {time.time()-start:.1f}â€¯s\")\nprint(\"ğŸ” Best iteration:\", model.best_iteration)\nprint(\"ğŸ BestÂ valÂ RMSE:\", model.best_score)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T08:49:41.873144Z","iopub.execute_input":"2025-06-14T08:49:41.873521Z","iopub.status.idle":"2025-06-14T09:23:57.598562Z","shell.execute_reply.started":"2025-06-14T08:49:41.873499Z","shell.execute_reply":"2025-06-14T09:23:57.596780Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [08:49:41] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"enable_categorical\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"[0]\tval-rmse:11.53022\n[250]\tval-rmse:9.30236\n[500]\tval-rmse:6.57608\n[750]\tval-rmse:4.48289\n[1000]\tval-rmse:3.07405\n[1250]\tval-rmse:2.20035\n[1500]\tval-rmse:1.54698\n[1750]\tval-rmse:1.09824\n[2000]\tval-rmse:0.77363\n[2250]\tval-rmse:0.55098\n[2500]\tval-rmse:0.39761\n[2750]\tval-rmse:0.28674\n[3000]\tval-rmse:0.21577\n[3250]\tval-rmse:0.16657\n[3500]\tval-rmse:0.13309\n[3750]\tval-rmse:0.10816\n[4000]\tval-rmse:0.09129\n[4250]\tval-rmse:0.07856\n[4500]\tval-rmse:0.06928\n[4750]\tval-rmse:0.06222\n[4999]\tval-rmse:0.05681\nâ±ï¸  Training time: 2055.7â€¯s\nğŸ” Best iteration: 4999\nğŸ BestÂ valÂ RMSE: 0.05681306002656589\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# â”€â”€ 7.  Predict on test & create submission â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ntest_preds = model.predict(dtest, iteration_range=(0, model.best_iteration + 1))\nsubmission = pd.DataFrame({ID_COL: test_df[ID_COL], TARGET: test_preds})\nsubmission.to_csv(\"submission_xgb.csv\", index=False)\nprint(\"âœ… submission_xgb.csv saved:\", submission.shape)\nsubmission.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T09:24:34.430216Z","iopub.execute_input":"2025-06-14T09:24:34.430588Z","iopub.status.idle":"2025-06-14T09:27:00.795464Z","shell.execute_reply.started":"2025-06-14T09:24:34.430563Z","shell.execute_reply":"2025-06-14T09:27:00.794617Z"}},"outputs":[{"name":"stdout","text":"âœ… submission_xgb.csv saved: (546874, 2)\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"   Unique ID  Lap_Time_Seconds\n0     288307         89.853821\n1     704288        104.082764\n2     951491         86.450500\n3    2591721        109.790520\n4    1202653         99.353638","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unique ID</th>\n      <th>Lap_Time_Seconds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>288307</td>\n      <td>89.853821</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>704288</td>\n      <td>104.082764</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>951491</td>\n      <td>86.450500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2591721</td>\n      <td>109.790520</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1202653</td>\n      <td>99.353638</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}